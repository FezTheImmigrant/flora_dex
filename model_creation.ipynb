{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "precise-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import H5pyHelper\n",
    "from tensorflow.keras import layers, models, regularizers, optimizers\n",
    "#from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "duplicate-newspaper",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "hf = h5py.File('/workspaces/flora_dex/h5_files/copies/data.h5', 'r')\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = hf['y_train'][0].shape[0] ## gets number of classes\n",
    "INP_SHAPE = hf['x_train'][0].shape\n",
    "TRAIN_SIZE = hf[\"x_train\"].shape[0]\n",
    "TEST_SIZE = hf[\"x_test\"].shape[0]\n",
    "\n",
    "\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "forced-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A memory-mapped array is kept on disk. However, it can be accessed and sliced like any ndarray.\n",
    "# Memory mapping is especially useful for accessing small fragments of large files without reading\n",
    "# the entire file into memory.\n",
    "\n",
    "#def generator(feature_name,label_name,batch_size,shuffle):\n",
    "#    index = 0\n",
    "#    \n",
    "#    hf = h5py.File('/home/sorozco0612/dev/flora_dex/raw_data/data.h5', 'a')\n",
    "#    \n",
    "#    # shuffle data\n",
    "#    if (shuffle):\n",
    "#        print(\"Shuffling data before starting training...\")\n",
    "#        #random.seed(datetime.now())\n",
    "#\n",
    "#        #random.shuffle(hf[feature_name])\n",
    "#        #random.shuffle(hf[label_name])\n",
    "#    \n",
    "#    while True:\n",
    "#        if index == 0:\n",
    "#    \n",
    "#            x = hf[feature_name]\n",
    "#            y = hf[label_name] \n",
    "#            \n",
    "#            ## create shuffle index for each batch\n",
    "#            idx_map = np.arange(x.shape[0])\n",
    "#            np.random.shuffle(idx_map)\n",
    "#        \n",
    "#        # batch has not met the end of the data\n",
    "#        if (index + batch_size < x.shape[0]):\n",
    "#            batch = sorted(idx_map[index:index+batch_size])\n",
    "#            features = x[batch]\n",
    "#            labels = y[batch]\n",
    "#\n",
    "#            index += batch_size\n",
    "#        else:\n",
    "#            # batch size will be smaller than the rest on last iteration \n",
    "#            \n",
    "#            batch = sorted(idx_map[index:])\n",
    "#            features = x[batch]\n",
    "#            labels = y[batch]\n",
    "#            \n",
    "#            idx_map = np.arange(features.shape[0])\n",
    "#            np.random.shuffle(idx_map)\n",
    "#\n",
    "#            index = 0\n",
    "#            \n",
    "#            ## close file so it can be reshuffled\n",
    "#            hf.close()\n",
    "#        \n",
    "#        ## shuffle just the batches\n",
    "#        #features = features[idx_map]\n",
    "#        #labels = labels[idx_map]\n",
    "#        \n",
    "#        yield (features,labels)\n",
    "        \n",
    "        \n",
    "def generator(feature_name,label_name,batch_size,shuffle):\n",
    "    index = 0\n",
    "    \n",
    "    \n",
    "    if (shuffle):\n",
    "        print(\"Shuffling data before starting training...\")\n",
    "        seed = datetime.now()\n",
    "        \n",
    "        H5pyHelper.shuffle_dataset(\n",
    "                    \"/home/sorozco0612/dev/flora_dex/raw_data/data.h5\", feature_name, seed\n",
    "                )\n",
    "        H5pyHelper.shuffle_dataset(\n",
    "                    \"/home/sorozco0612/dev/flora_dex/raw_data/data.h5\", label_name, seed\n",
    "                )\n",
    "    while True:\n",
    "        \n",
    "        if index == 0:\n",
    "            hf = h5py.File('/home/sorozco0612/dev/flora_dex/raw_data/data.h5', 'r')\n",
    "    \n",
    "            x = hf[feature_name]\n",
    "            y = hf[label_name]  \n",
    "        \n",
    "        # batch has not met the end of the data\n",
    "        if (index + batch_size < x.shape[0]):\n",
    "            features = x[index:index+batch_size]\n",
    "            labels = y[index:index+batch_size]\n",
    "            index += batch_size\n",
    "        else:\n",
    "            # batch size will be smaller than the rest on last iteration\n",
    "            features = x[index:]\n",
    "            labels = y[index:]\n",
    "            index = 0\n",
    "            \n",
    "            ## close file so it can be reshuffled\n",
    "            hf.close()\n",
    "            \n",
    "        yield (features,labels)   \n",
    "\n",
    "train_generator = generator('x_train', 'y_train',BATCH_SIZE,True)\n",
    "test_generator = generator('x_test','y_test',BATCH_SIZE,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interracial-identity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 123, 96)      34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 123, 123, 96)      384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 61, 61, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 61, 61, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 61, 61, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 384)       885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 30, 30, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30, 30, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 256)       884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 30, 30, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              205524992 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 102)               417894    \n",
      "=================================================================\n",
      "Total params: 226,476,902\n",
      "Trainable params: 226,474,150\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## alex net\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(500,500,3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(4096, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(4096, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "random-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.optimizers.SGD(lr=0.001), metrics=['accuracy'])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.optimizers.SGD(lr=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "understanding-decrease",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling data before starting training...\n",
      "'x_train' chunk has shape:(500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(1000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(1500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(2000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(2500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(3000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(3500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(4000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(4500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(5000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(5500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(6000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(6500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(7000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(7500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(8000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(8500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(9000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(9500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(10000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(10500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(11000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(11500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(12000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(12500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(13000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(13500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(14000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(14500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(15000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(15500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(16000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(16500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(17000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(17500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(18000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(18500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(19000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(19500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(20000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(20500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(21000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(21500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(22000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(22500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(23000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(23500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(24000, 500, 500, 3)\n",
      "'x_train' chunk has shape:(24500, 500, 500, 3)\n",
      "'x_train' chunk has shape:(24579, 500, 500, 3)\n",
      "'y_train' chunk has shape:(500, 102)\n",
      "'y_train' chunk has shape:(1000, 102)\n",
      "'y_train' chunk has shape:(1500, 102)\n",
      "'y_train' chunk has shape:(2000, 102)\n",
      "'y_train' chunk has shape:(2500, 102)\n",
      "'y_train' chunk has shape:(3000, 102)\n",
      "'y_train' chunk has shape:(3500, 102)\n",
      "'y_train' chunk has shape:(4000, 102)\n",
      "'y_train' chunk has shape:(4500, 102)\n",
      "'y_train' chunk has shape:(5000, 102)\n",
      "'y_train' chunk has shape:(5500, 102)\n",
      "'y_train' chunk has shape:(6000, 102)\n",
      "'y_train' chunk has shape:(6500, 102)\n",
      "'y_train' chunk has shape:(7000, 102)\n",
      "'y_train' chunk has shape:(7500, 102)\n",
      "'y_train' chunk has shape:(8000, 102)\n",
      "'y_train' chunk has shape:(8500, 102)\n",
      "'y_train' chunk has shape:(9000, 102)\n",
      "'y_train' chunk has shape:(9500, 102)\n",
      "'y_train' chunk has shape:(10000, 102)\n",
      "'y_train' chunk has shape:(10500, 102)\n",
      "'y_train' chunk has shape:(11000, 102)\n",
      "'y_train' chunk has shape:(11500, 102)\n",
      "'y_train' chunk has shape:(12000, 102)\n",
      "'y_train' chunk has shape:(12500, 102)\n",
      "'y_train' chunk has shape:(13000, 102)\n",
      "'y_train' chunk has shape:(13500, 102)\n",
      "'y_train' chunk has shape:(14000, 102)\n",
      "'y_train' chunk has shape:(14500, 102)\n",
      "'y_train' chunk has shape:(15000, 102)\n",
      "'y_train' chunk has shape:(15500, 102)\n",
      "'y_train' chunk has shape:(16000, 102)\n",
      "'y_train' chunk has shape:(16500, 102)\n",
      "'y_train' chunk has shape:(17000, 102)\n",
      "'y_train' chunk has shape:(17500, 102)\n",
      "'y_train' chunk has shape:(18000, 102)\n",
      "'y_train' chunk has shape:(18500, 102)\n",
      "'y_train' chunk has shape:(19000, 102)\n",
      "'y_train' chunk has shape:(19500, 102)\n",
      "'y_train' chunk has shape:(20000, 102)\n",
      "'y_train' chunk has shape:(20500, 102)\n",
      "'y_train' chunk has shape:(21000, 102)\n",
      "'y_train' chunk has shape:(21500, 102)\n",
      "'y_train' chunk has shape:(22000, 102)\n",
      "'y_train' chunk has shape:(22500, 102)\n",
      "'y_train' chunk has shape:(23000, 102)\n",
      "'y_train' chunk has shape:(23500, 102)\n",
      "'y_train' chunk has shape:(24000, 102)\n",
      "'y_train' chunk has shape:(24500, 102)\n",
      "'y_train' chunk has shape:(24579, 102)\n",
      "Epoch 1/250\n",
      "768/768 [==============================] - 397s 512ms/step - loss: 5.4977 - accuracy: 0.0145 - val_loss: 4.4390 - val_accuracy: 0.0404\n",
      "Epoch 2/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 4.5192 - accuracy: 0.0254 - val_loss: 4.2071 - val_accuracy: 0.0586\n",
      "Epoch 3/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 4.3302 - accuracy: 0.0427 - val_loss: 4.0474 - val_accuracy: 0.0774\n",
      "Epoch 4/250\n",
      "768/768 [==============================] - 391s 510ms/step - loss: 4.1727 - accuracy: 0.0564 - val_loss: 3.8776 - val_accuracy: 0.1082\n",
      "Epoch 5/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 4.0089 - accuracy: 0.0764 - val_loss: 3.7150 - val_accuracy: 0.1300\n",
      "Epoch 6/250\n",
      "768/768 [==============================] - 391s 510ms/step - loss: 3.8488 - accuracy: 0.1056 - val_loss: 3.5932 - val_accuracy: 0.1531\n",
      "Epoch 7/250\n",
      "768/768 [==============================] - 391s 510ms/step - loss: 3.6732 - accuracy: 0.1327 - val_loss: 3.4792 - val_accuracy: 0.1715\n",
      "Epoch 8/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 3.5399 - accuracy: 0.1532 - val_loss: 3.3556 - val_accuracy: 0.1899\n",
      "Epoch 9/250\n",
      "768/768 [==============================] - 391s 510ms/step - loss: 3.3907 - accuracy: 0.1818 - val_loss: 3.2522 - val_accuracy: 0.2118\n",
      "Epoch 10/250\n",
      "768/768 [==============================] - 391s 510ms/step - loss: 3.2412 - accuracy: 0.2101 - val_loss: 3.1496 - val_accuracy: 0.2318\n",
      "Epoch 11/250\n",
      "768/768 [==============================] - 392s 510ms/step - loss: 3.0822 - accuracy: 0.2412 - val_loss: 3.0737 - val_accuracy: 0.2445\n",
      "Epoch 12/250\n",
      "768/768 [==============================] - 391s 510ms/step - loss: 2.9505 - accuracy: 0.2659 - val_loss: 2.9823 - val_accuracy: 0.2654\n",
      "Epoch 13/250\n",
      "768/768 [==============================] - 391s 510ms/step - loss: 2.8098 - accuracy: 0.2932 - val_loss: 2.9220 - val_accuracy: 0.2794\n",
      "Epoch 14/250\n",
      "768/768 [==============================] - 391s 510ms/step - loss: 2.6684 - accuracy: 0.3236 - val_loss: 2.8274 - val_accuracy: 0.2987\n",
      "Epoch 15/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 2.5135 - accuracy: 0.3592 - val_loss: 2.7545 - val_accuracy: 0.3135\n",
      "Epoch 16/250\n",
      "768/768 [==============================] - 391s 510ms/step - loss: 2.3468 - accuracy: 0.3948 - val_loss: 2.6676 - val_accuracy: 0.3359\n",
      "Epoch 17/250\n",
      "768/768 [==============================] - 391s 510ms/step - loss: 2.1981 - accuracy: 0.4307 - val_loss: 2.5931 - val_accuracy: 0.3467\n",
      "Epoch 18/250\n",
      "768/768 [==============================] - 392s 510ms/step - loss: 2.0466 - accuracy: 0.4651 - val_loss: 2.5364 - val_accuracy: 0.3595\n",
      "Epoch 19/250\n",
      "768/768 [==============================] - 391s 510ms/step - loss: 1.9178 - accuracy: 0.4951 - val_loss: 2.4628 - val_accuracy: 0.3794\n",
      "Epoch 20/250\n",
      "768/768 [==============================] - 391s 510ms/step - loss: 1.7504 - accuracy: 0.5372 - val_loss: 2.4072 - val_accuracy: 0.3887\n",
      "Epoch 21/250\n",
      "768/768 [==============================] - 391s 510ms/step - loss: 1.6177 - accuracy: 0.5687 - val_loss: 2.3760 - val_accuracy: 0.4010\n",
      "Epoch 22/250\n",
      "768/768 [==============================] - 392s 510ms/step - loss: 1.4707 - accuracy: 0.6059 - val_loss: 2.3044 - val_accuracy: 0.4120\n",
      "Epoch 23/250\n",
      "768/768 [==============================] - 391s 510ms/step - loss: 1.3466 - accuracy: 0.6375 - val_loss: 2.2796 - val_accuracy: 0.4255\n",
      "Epoch 24/250\n",
      "768/768 [==============================] - 391s 510ms/step - loss: 1.2098 - accuracy: 0.6739 - val_loss: 2.2340 - val_accuracy: 0.4330\n",
      "Epoch 25/250\n",
      "768/768 [==============================] - 391s 510ms/step - loss: 1.1074 - accuracy: 0.7044 - val_loss: 2.1288 - val_accuracy: 0.4591\n",
      "Epoch 26/250\n",
      "768/768 [==============================] - 391s 510ms/step - loss: 0.9850 - accuracy: 0.7368 - val_loss: 2.2057 - val_accuracy: 0.4476\n",
      "Epoch 27/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.8818 - accuracy: 0.7675 - val_loss: 2.1191 - val_accuracy: 0.4641\n",
      "Epoch 28/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.7976 - accuracy: 0.7900 - val_loss: 2.0953 - val_accuracy: 0.4696\n",
      "Epoch 29/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.7040 - accuracy: 0.8169 - val_loss: 2.1770 - val_accuracy: 0.4580\n",
      "Epoch 30/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.6303 - accuracy: 0.8390 - val_loss: 2.0308 - val_accuracy: 0.4886\n",
      "Epoch 31/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.5589 - accuracy: 0.8589 - val_loss: 1.9874 - val_accuracy: 0.4988\n",
      "Epoch 32/250\n",
      "768/768 [==============================] - 391s 510ms/step - loss: 0.5079 - accuracy: 0.8742 - val_loss: 1.9847 - val_accuracy: 0.4980\n",
      "Epoch 33/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.4476 - accuracy: 0.8896 - val_loss: 1.9999 - val_accuracy: 0.5007\n",
      "Epoch 34/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.3997 - accuracy: 0.9049 - val_loss: 1.9670 - val_accuracy: 0.5081\n",
      "Epoch 35/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.3675 - accuracy: 0.9094 - val_loss: 1.9420 - val_accuracy: 0.5160\n",
      "Epoch 36/250\n",
      "768/768 [==============================] - 391s 510ms/step - loss: 0.3327 - accuracy: 0.9207 - val_loss: 1.9398 - val_accuracy: 0.5153\n",
      "Epoch 37/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.2989 - accuracy: 0.9282 - val_loss: 1.9307 - val_accuracy: 0.5170\n",
      "Epoch 38/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.2679 - accuracy: 0.9383 - val_loss: 1.9272 - val_accuracy: 0.5227\n",
      "Epoch 39/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.2490 - accuracy: 0.9443 - val_loss: 1.9254 - val_accuracy: 0.5250\n",
      "Epoch 40/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.2152 - accuracy: 0.9506 - val_loss: 1.9302 - val_accuracy: 0.5270\n",
      "Epoch 41/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.2070 - accuracy: 0.9530 - val_loss: 1.9321 - val_accuracy: 0.5232\n",
      "Epoch 42/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.1894 - accuracy: 0.9577 - val_loss: 1.9224 - val_accuracy: 0.5272\n",
      "Epoch 43/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.1794 - accuracy: 0.9598 - val_loss: 1.9199 - val_accuracy: 0.5326\n",
      "Epoch 44/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.1717 - accuracy: 0.9629 - val_loss: 1.8952 - val_accuracy: 0.5377\n",
      "Epoch 45/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.1515 - accuracy: 0.9677 - val_loss: 1.9221 - val_accuracy: 0.5337\n",
      "Epoch 46/250\n",
      "768/768 [==============================] - 391s 510ms/step - loss: 0.1441 - accuracy: 0.9684 - val_loss: 1.9320 - val_accuracy: 0.5344\n",
      "Epoch 47/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.1423 - accuracy: 0.9683 - val_loss: 1.9059 - val_accuracy: 0.5410\n",
      "Epoch 48/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.1309 - accuracy: 0.9714 - val_loss: 1.8903 - val_accuracy: 0.5388\n",
      "Epoch 49/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.1190 - accuracy: 0.9743 - val_loss: 1.9058 - val_accuracy: 0.5433\n",
      "Epoch 50/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.1115 - accuracy: 0.9754 - val_loss: 1.8934 - val_accuracy: 0.5453\n",
      "Epoch 51/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.1030 - accuracy: 0.9787 - val_loss: 1.8937 - val_accuracy: 0.5469\n",
      "Epoch 52/250\n",
      "768/768 [==============================] - 392s 510ms/step - loss: 0.1003 - accuracy: 0.9785 - val_loss: 1.9093 - val_accuracy: 0.5444\n",
      "Epoch 53/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.0965 - accuracy: 0.9802 - val_loss: 1.8710 - val_accuracy: 0.5496\n",
      "Epoch 54/250\n",
      "768/768 [==============================] - 390s 509ms/step - loss: 0.0937 - accuracy: 0.9793 - val_loss: 1.8858 - val_accuracy: 0.5466\n",
      "Epoch 55/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.0869 - accuracy: 0.9825 - val_loss: 1.9085 - val_accuracy: 0.5442\n",
      "Epoch 56/250\n",
      "768/768 [==============================] - 391s 509ms/step - loss: 0.0807 - accuracy: 0.9839 - val_loss: 1.9172 - val_accuracy: 0.5443\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
    "fit = model.fit(x=train_generator,\n",
    "                steps_per_epoch= TRAIN_SIZE // BATCH_SIZE,\n",
    "                callbacks=[callback], \n",
    "                validation_steps= TEST_SIZE // BATCH_SIZE,\n",
    "                validation_data=test_generator,\n",
    "                verbose=1,\n",
    "                epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "opponent-burden",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "[[7.78542657e-04 6.25980692e-03 9.49958712e-02 1.29004084e-05\n",
      "  6.21830477e-05 5.54712933e-05 2.84315720e-05 3.81550693e-04\n",
      "  1.92087628e-02 2.98860745e-04 1.75059104e-05 3.02061118e-04\n",
      "  1.28012864e-04 7.46248243e-03 2.92857840e-05 6.32313604e-04\n",
      "  2.79471148e-02 5.68286690e-04 1.14611199e-03 1.32118255e-01\n",
      "  4.49791871e-04 1.97634473e-03 5.33298917e-05 3.50706745e-04\n",
      "  2.56427709e-04 5.84588743e-05 2.45174942e-05 2.47118487e-06\n",
      "  5.11093007e-04 3.84321646e-03 1.58055336e-03 1.88186527e-06\n",
      "  2.32173683e-04 1.27475723e-05 4.45285914e-05 2.21634018e-05\n",
      "  5.67492934e-05 2.46388634e-04 3.09811076e-05 8.77393322e-05\n",
      "  4.78481001e-04 5.64316381e-03 1.18022166e-04 1.27222916e-06\n",
      "  9.34274431e-05 2.84610323e-05 2.83514528e-04 2.32970024e-06\n",
      "  1.88430408e-06 6.76734408e-06 8.66164701e-05 3.97296157e-03\n",
      "  1.50364509e-03 5.61339766e-06 7.86752134e-05 8.37487678e-05\n",
      "  3.24041976e-05 1.74921606e-05 7.08757943e-06 1.66228929e-05\n",
      "  1.90709488e-05 2.80225231e-06 3.80638812e-04 1.44820660e-03\n",
      "  2.63480688e-05 7.08021253e-05 1.70028026e-04 3.28403711e-03\n",
      "  8.53034481e-03 2.40584792e-04 1.54948758e-03 8.89394665e-04\n",
      "  7.45455443e-04 9.55210999e-03 1.85796351e-03 8.24846848e-06\n",
      "  4.58282866e-02 2.16347980e-03 5.20173907e-02 1.58027709e-02\n",
      "  1.41339796e-03 1.10333995e-03 1.90447981e-03 2.29206325e-05\n",
      "  3.80926281e-01 1.45545884e-04 2.34326278e-03 2.92220786e-02\n",
      "  1.86614564e-03 6.73532262e-02 4.19766817e-04 1.52312741e-05\n",
      "  4.90302686e-03 4.81088413e-03 1.49035510e-02 2.24525633e-04\n",
      "  3.38699408e-07 1.04378769e-05 1.89727725e-05 2.53649615e-03\n",
      "  4.14946437e-04 2.61154342e-02]]\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def summarize_prediction(Y_true, Y_pred):\n",
    "    #mse = mean_squared_error(Y_true, Y_pred)\n",
    "    #accuracy = accuracy_score(Y_true, Y_pred)\n",
    "    #print(f'mse       = {mse:.2}')\n",
    "    print(f'accuracy = {accuracy:.2%}')\n",
    "    \n",
    "def predict_and_summarize(X, Y):\n",
    "    Y_pred = model.predict(X)\n",
    "    #summarize_prediction(Y, Y_pred)\n",
    "    return Y_pred\n",
    "\n",
    "hf = h5py.File('/home/sorozco0612/dev/flora_dex/raw_data/data.h5', 'r')\n",
    "x_test = hf[\"x_test\"]\n",
    "y_test = hf[\"y_test\"]\n",
    "\n",
    "y_pred = predict_and_summarize(x_test, y_test)\n",
    "\n",
    "print(y_pred[:1])\n",
    "print(y_test[:1])\n",
    "\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-employer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}